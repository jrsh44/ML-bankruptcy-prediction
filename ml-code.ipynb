{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Bankruptcy Prediction\n",
    "\n",
    "### Cel biznesowy\n",
    "Predykcja brankructwa firm na podstawie parametrów ekonomicznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_raw = pd.read_csv('./db/data.csv') \n",
    "db_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "Sprawdzenie wartości null w danych kolumnach\n",
    "\n",
    "**Wniosek**: brak wratości null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie ile firm zbankrutowało, a ile nie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_raw['Bankrupt?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyrzucenie ' Net Income Flag' - 0 dla każdego recordu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_raw.drop([' Net Income Flag'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podzielenie na zbiór treningowy i walidacyjny do sprawdzenia poprawności założeń\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = db['Bankrupt?']\n",
    "db = db.drop(['Bankrupt?'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_temp, x_valid, y_temp, y_valid = train_test_split(db, target, test_size=0.3, stratify = target, random_state = 42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_temp, y_temp, test_size=0.3, stratify = y_temp, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie zależności miedzy bankrupctwem a pozostałymi parametrami celem wyszczególenia tych najbardziej istotnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 20):\n",
    "    fig, ax = plt.subplots(figsize=(25,8))\n",
    "    sns.boxplot(x=y_train, y=x_train[x_train.columns[i]], ax=ax)\n",
    "    ax.set_title(f'Boxplot of {x_train.columns[i]}')\n",
    "    print(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oraz za pomocą heatmapy korelacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr = db.corr('spearman')\n",
    "mask = np.triu(np.ones_like(spearman_corr, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(spearman_corr, mask=mask, square=True, linewidths=0.5, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybór kolumn z najbardziej widocznymi zależnościami do dalszych badań korelacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spearman_corr['Bankrupt?'].sort_values(ascending=False).head(15))\n",
    "print(spearman_corr['Bankrupt?'].sort_values(ascending=False).tail(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wizualizacja kilku ciekawych parametrów za pomocą boxplotów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(ncols=5, figsize=(25,8))\n",
    "\n",
    "sns.boxplot(x='Bankrupt?', y=\" Persistent EPS in the Last Four Seasons\", data=db, ax=plt.subplot(1, 5, 1))\n",
    "sns.boxplot(x='Bankrupt?', y=\" Net Income to Total Assets\", data=db, ax=plt.subplot(1, 5, 2))\n",
    "sns.boxplot(x='Bankrupt?', y=\" ROA(B) before interest and depreciation after tax\", data=db, ax=plt.subplot(1, 5, 3))\n",
    "sns.boxplot(x='Bankrupt?', y=\" Net Value Per Share (B)\", data=db, ax=plt.subplot(1, 5, 4))\n",
    "sns.boxplot(x='Bankrupt?', y=\" Equity to Long-term Liability\", data=db, ax=plt.subplot(1, 5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsługa outlierów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in x_train.columns:\n",
    "    upper_lim = x_train[column].quantile(.98)\n",
    "    lower_lim = x_train[column].quantile(.02)\n",
    "\n",
    "    x_train.loc[x_train[column] > upper_lim, column] = upper_lim\n",
    "    x_train.loc[x_train[column] < lower_lim, column] = lower_lim\n",
    "\n",
    "    x_test.loc[x_test[column] > upper_lim, column] = upper_lim\n",
    "    x_test.loc[x_test[column] < lower_lim, column] = lower_lim\n",
    "    \n",
    "    x_valid.loc[x_valid[column] > upper_lim, column] = upper_lim\n",
    "    x_valid.loc[x_valid[column] < lower_lim, column] = lower_lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarytm kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in x_train.columns:\n",
    "    skew = x_train[column].skew()\n",
    "    if skew > 0.5 or skew < -0.5:\n",
    "        x_train[column] = np.log1p(x_train[column])  \n",
    "        x_test[column] = np.log1p(x_test[column])  \n",
    "        x_valid[column] = np.log1p(x_valid[column])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(x_train)\n",
    "\n",
    "x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)\n",
    "x_valid = pd.DataFrame(scaler.transform(x_valid), columns=x_valid.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wybór najbardziej istotnych cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=69)\n",
    "rf_model.fit(x_train, y_train)\n",
    "perm_importance = permutation_importance(rf_model, x_train, y_train, n_repeats=100, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "top_vars = 40\n",
    "\n",
    "x_test = x_test[x_train.columns[sorted_idx][-top_vars:]]\n",
    "x_valid = x_valid[x_train.columns[sorted_idx][-top_vars:]]\n",
    "x_train = x_train[x_train.columns[sorted_idx][-top_vars:]]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(range(top_vars), perm_importance.importances_mean[sorted_idx][-top_vars:], color='skyblue')\n",
    "plt.yticks(range(top_vars), x_train.columns)\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 10, figsize=(25, 25))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        column_index = i * 10 + j\n",
    "        if column_index < len(db.columns):\n",
    "            sns.kdeplot(db[db.columns[column_index]], ax=axs[i, j])\n",
    "            axs[i, j].set_title(f'Density plot of {db.columns[column_index]}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 10, figsize=(25, 25))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        column_index = i * 10 + j\n",
    "        if column_index < len(db.columns):\n",
    "            sns.kdeplot(db[db.columns[column_index]], ax=axs[i, j])\n",
    "            axs[i, j].set_title(f'Density plot of {db.columns[column_index]}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwsze testowanie modeli: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'max_iter': list(range(100,800,100)),\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=3, cv=5)\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "best_estimator = grid.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = grid.best_estimator_\n",
    "\n",
    "y_pred = best_estimator.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "gini = 2 * roc_auc - 1\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R^2: {r2}')\n",
    "print('-'*30)\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print('-'*30)\n",
    "print(f'ROC_AUC: {roc_auc}')\n",
    "print(f'GINI: {gini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "gini = 2 * roc_auc - 1\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R^2: {r2}')\n",
    "print('-'*30)\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {f1}')\n",
    "print('-'*30)\n",
    "print(f'ROC_AUC: {roc_auc}')\n",
    "print(f'GINI: {gini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "log_fpr, log_tpr, log_thresold = roc_curve(y_test, best_estimator)\n",
    "\n",
    "\n",
    "\n",
    "def graph_roc_curve_multiple(log_fpr, log_tpr):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.title('ROC Curve', fontsize=14)\n",
    "    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_test, best_estimator)))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([-0.01, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=13)\n",
    "    plt.ylabel('True Positive Rate', fontsize=13)\n",
    "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
    "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
    "                )\n",
    "    plt.legend()\n",
    "    \n",
    "graph_roc_curve_multiple(log_fpr, log_tpr)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
